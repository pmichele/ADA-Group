{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import os\n",
    "import folium\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to load the data and vectorize it using tf-idf, this way we will later be able to learn from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading data and vectorizing if using tf-idf\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(newsgroups_train.data)\n",
    "y = newsgroups_train.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function just allows to split the data as we want: it is already possible to do so with a function from the scikit library, but having our own let's us have total control over what it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    Splits the dataset based on the split ratio\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate random indices\n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_train = indices[: index_split]\n",
    "    index_test = indices[index_split:]\n",
    "    \n",
    "    # Create split\n",
    "    x_1 = x[index_train]\n",
    "    x_2 = x[index_test]\n",
    "    y_1 = y[index_train]\n",
    "    y_2 = y[index_test]\n",
    "    \n",
    "    return x_1, x_2, y_1, y_2\n",
    "\n",
    "x_train, x_test_val, y_train, y_test_val = split_data(x, y, 0.8)\n",
    "x_test, x_val, y_test, y_val = split_data(x_test_val, y_test_val, 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the score function is re-written (it already exists in the scikit library), but this way we can fine tune it if we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(y_test_f, rf_probs_f):\n",
    "    \"\"\"\n",
    "    This function will show the scores from the probabilities in rf_probs_f\n",
    "    This will also result the final score in [0,1]\n",
    "    rf.score(x_test, y_test) could be used as well, but this way we can fine tune this score function if needed\n",
    "    \"\"\"\n",
    "    rf_pred = np.zeros(len(y_test_f))\n",
    "    count = 0\n",
    "    for index, probs in enumerate(rf_probs_f):\n",
    "        \n",
    "        # Looking for the maximum probability\n",
    "        max_index, max_prob = 0, 0\n",
    "        for ind, prob in enumerate(probs):\n",
    "            if (max_prob < prob):\n",
    "                max_index = ind\n",
    "                max_prob = prob\n",
    "        \n",
    "        rf_pred[index] = max_index\n",
    "        # Now we can compare it to the real value\n",
    "        if (max_index == y_test_f[index]):\n",
    "            count += 1\n",
    "            \n",
    "    count /= len(y_test_f)\n",
    "    print(\"{a}% of correct guesses with a random forest\".format(a=count*100))\n",
    "    return count, rf_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will grid search through the hyperparameters in order to find the best score and the corresponding hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gridsearch_params(x_train_f, y_train_f, x_test_f, y_test_f, max_depth_range, features_range, estimators_range, seed=1):\n",
    "    best_pred = np.zeros(len(y_test_f))\n",
    "    best_score = 0\n",
    "    best_max_depth = 0\n",
    "    best_max_features = 0\n",
    "    best_n_estimators = 0\n",
    "    \n",
    "    # Grid searching through the parameters\n",
    "    for max_depth in max_depth_range:\n",
    "        for max_features in features_range:\n",
    "            for n_estimators in estimators_range:\n",
    "                rf = RandomForestClassifier(max_depth=max_depth, max_features=max_features, n_estimators=n_estimators, random_state=seed)\n",
    "                rf.fit(x_train_f, y_train_f)\n",
    "                rf_probs = rf.predict_proba(x_test_f)\n",
    "                test_score, rf_pred = score(y_test_f, rf_probs)\n",
    "\n",
    "                # Finding if this is the best score yet\n",
    "                if (best_score < test_score):\n",
    "                    best_pred = rf_pred\n",
    "                    best_score = test_score\n",
    "                    best_max_depth = max_depth\n",
    "                    best_max_features = max_features\n",
    "                    best_n_estimators = n_estimators\n",
    "                \n",
    "    print(\"Found a best score of {a}% for {b} max_depth, {c} max_features and {d} n_estimators\".format(a=best_score*100, b=best_max_depth, c=best_max_features, d=best_n_estimators))\n",
    "    return best_pred, best_score, best_max_depth, best_max_features, best_n_estimators\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start a grid search to determine a good maximum number of features (for the estimators range and the maximum depth range, the higher the better, but this is at a igh computation cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.748894783377544% of correct guesses with a random forest\n",
      "69.76127320954907% of correct guesses with a random forest\n",
      "70.29177718832891% of correct guesses with a random forest\n",
      "70.11494252873564% of correct guesses with a random forest\n",
      "70.99911582670202% of correct guesses with a random forest\n",
      "68.34659593280283% of correct guesses with a random forest\n",
      "69.05393457117594% of correct guesses with a random forest\n",
      "Found a best score of 70.99911582670202% for 10 max_depth, 1000 max_features and 100 n_estimators\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 18.,   8.,  16., ...,  10.,   6.,   6.]),\n",
       " 0.7099911582670203,\n",
       " 10,\n",
       " 1000,\n",
       " 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First grid search: looking for something globally, studying for one estimator range and one depth\n",
    "max_depth_range = [10]\n",
    "features_range = [100, 500, 800, 900, 1000, 1100, 1200]\n",
    "estimators_range = [100]\n",
    "gridsearch_params(x_train, y_train, x_test, y_test, max_depth_range, features_range, estimators_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try on some custom hyperparameters with a very high max_depth, using the optimal feature range we found before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.67020335985853% of correct guesses with a random forest\n",
      "Found a best score of 82.67020335985853% for 100 max_depth, 1000 max_features and 100 n_estimators\n"
     ]
    }
   ],
   "source": [
    "# With good parameters, using 1000 max number of features\n",
    "max_depth_range = [100]\n",
    "features_range = [1000]\n",
    "estimators_range = [100]\n",
    "best_pred, best_score, best_max_depth, best_max_features, best_n_estimators = gridsearch_params(x_train, y_train, x_test, y_test, max_depth_range, features_range, estimators_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we finally have around 83% of matches, which is a decent amount given that we are working with text.\n",
    "With the prediction we just computed, we can easily build the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "0: alt.atheism\n",
      "1: comp.graphics\n",
      "2: comp.os.ms-windows.misc\n",
      "3: comp.sys.ibm.pc.hardware\n",
      "4: comp.sys.mac.hardware\n",
      "5: comp.windows.x\n",
      "6: misc.forsale\n",
      "7: rec.autos\n",
      "8: rec.motorcycles\n",
      "9: rec.sport.baseball\n",
      "10: rec.sport.hockey\n",
      "11: sci.crypt\n",
      "12: sci.electronics\n",
      "13: sci.med\n",
      "14: sci.space\n",
      "15: soc.religion.christian\n",
      "16: talk.politics.guns\n",
      "17: talk.politics.mideast\n",
      "18: talk.politics.misc\n",
      "19: talk.religion.misc\n",
      "\n",
      "\n",
      "[[44  0  0  0  0  0  0  0  0  0  0  0  1  0  0 10  0  0  1  2]\n",
      " [ 0 30  8  3  4  5  2  0  0  1  0  0  2  1  1  0  0  0  1  0]\n",
      " [ 0  4 40  2  0  1  1  0  0  0  0  0  1  0  1  0  0  0  1  0]\n",
      " [ 0  1  7 45  3  1  4  1  1  0  0  2  1  0  0  0  0  0  1  0]\n",
      " [ 0  2  0  3 43  0  2  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  2  1  0  0 53  0  0  0  1  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  1  0  0 47  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  1 51  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  1  0  1  1 61  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  1  2  0  0 52  2  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2 55  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  0  0  0  0  0  1  0  0 57  1  0  0  1  0  1  0  0]\n",
      " [ 0  2  1  2  2  1  3  2  0  1  1  1 39  1  2  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  1  0  0  0  3 53  1  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  1  0  0  2  0  0  1  0 44  0  0  1  0  0]\n",
      " [ 2  2  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  1  0  2  0  0  2  0 62  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  1  0 49  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  0  0  0  0  0  1  2  2  5  0 33  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  2  0  0  0  0  0 11  1  0  0 17]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels:\")\n",
    "for i in range(20):\n",
    "    print(\"{a}: \".format(a=i) + newsgroups_train.target_names[i])\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_test, best_pred, labels=[i for i in range (20)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this confusion matrix clearly shows that the system does a good job at classifying the articles.\n",
    "If we study the last case (last line in the matrix), which is talk.religion.misc (label 19), we can see that there are 17 correct matches, and 11 matches with soc.religion.christian (label 15), which totally makes sense since those two subjects are extremly close (so the system has a harder time distinguishing them)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
