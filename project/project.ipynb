{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project Description</h1><br>\n",
    "The purpose of this project is to:\n",
    "<ul>\n",
    "<li>See the popularity of Trump's tweets across countries</li>\n",
    "<li>Perform a sentiment analysis of recent tweets by Trump across countries</li>\n",
    "<li>See if similar reactions occur if his tweets are talking about the same topic</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Collection</h1>\n",
    "\n",
    "<h2>Trump tweets data</h2>\n",
    "\n",
    "We utilised the several datasets available at https://github.com/bpb27/trump_tweet_data_archive which happens to automatically updata Trump's tweets every hour. All of the datasets are saved in json format and the data contained in them is the result of calls to the Twitter API. There are two varients, <b>master</b> which contains all of the original information from the API call and <b>condensed</b> which contains a lot less but essential information. After looking through some of the master and condensed datasets, we decided that the condensed datasets were sufficient as they contained the specfic fields we required and the entries in master were unnecessarily large for our purpose (too much information that we would not use). <br>\n",
    "\n",
    "We're using all of the condensed datasets from 2009 to 2017 because the tweet data isn't that time consuming to process and having as much data as possible will be beneficial when clustering the messages in the tweets. Since the 2017 datatset is continiously being updated, we are only using it up to a certain date. All of the data in total is around 10 MB so it is really simple to handle and there is no need to rely on additional computing resources<br>\n",
    "\n",
    "Below, we import all the necessary libraries we need for extracting and combining the data. We iterate over each json file and turn them into a pandas DataFrame and store them in the list <b>data</b>. We do this so that later on we can simply combine them into one single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create empty list to store all of our data\n",
    "data=[]\n",
    "\n",
    "#Add data from 2009 to 2017, 2017 data obtained 28/11/2017\n",
    "data.append(pd.DataFrame(json.load(open(\"data/condensed_2009.json\"))))\n",
    "for i in range(10,18):\n",
    "    fileName=\"data/condensed_20\"+str(i)+\".json\"\n",
    "    data.append(pd.DataFrame(json.load(open(fileName))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine all of our seperate datasets into one pandas dataframe. We also set the id of the dataframe to <b>id_str</b> since we already know that each of the ids are unique. we also have to convert the <b>created_at</b> attribute into a Date object so that the dataframe is able to properly sort tweets by date (if it was still a string then it would sort incorrectly as it would put tweets starting on a Friday first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine all of the individual datasets together\n",
    "df = pd.concat(data)\n",
    "\n",
    "#Set the index\n",
    "df = df.set_index(\"id_str\")\n",
    "\n",
    "#Convert to Date\n",
    "df[\"created_at\"]=pd.to_datetime(df[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1698308935</th>\n",
       "      <td>2009-05-04 18:54:25</td>\n",
       "      <td>202</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>253</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701461182</th>\n",
       "      <td>2009-05-05 01:00:10</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737479987</th>\n",
       "      <td>2009-05-08 13:38:08</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741160716</th>\n",
       "      <td>2009-05-08 20:40:15</td>\n",
       "      <td>27</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773561338</th>\n",
       "      <td>2009-05-12 14:07:28</td>\n",
       "      <td>1950</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1421</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_at  favorite_count in_reply_to_user_id_str  \\\n",
       "id_str                                                                   \n",
       "1698308935 2009-05-04 18:54:25             202                    None   \n",
       "1701461182 2009-05-05 01:00:10               3                    None   \n",
       "1737479987 2009-05-08 13:38:08               2                    None   \n",
       "1741160716 2009-05-08 20:40:15              27                    None   \n",
       "1773561338 2009-05-12 14:07:28            1950                    None   \n",
       "\n",
       "            is_retweet  retweet_count              source  \\\n",
       "id_str                                                      \n",
       "1698308935       False            253  Twitter Web Client   \n",
       "1701461182       False              2  Twitter Web Client   \n",
       "1737479987       False              3  Twitter Web Client   \n",
       "1741160716       False              8  Twitter Web Client   \n",
       "1773561338       False           1421  Twitter Web Client   \n",
       "\n",
       "                                                         text  \n",
       "id_str                                                         \n",
       "1698308935  Be sure to tune in and watch Donald Trump on L...  \n",
       "1701461182  Donald Trump will be appearing on The View tom...  \n",
       "1737479987  Donald Trump reads Top Ten Financial Tips on L...  \n",
       "1741160716  New Blog Post: Celebrity Apprentice Finale and...  \n",
       "1773561338  \"My persona will never be that of a wallflower...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"created_at\",inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Reply tweets data</h2>\n",
    "\n",
    "In order to do a sentiment analysis, we need to create a dataframe containing replies to Trump's tweets. To do this, we use the library Twarc which simplifies the API call process. Note that due to a limitation in the Twitter API, getting replies to a tweet is not a feature by default so you have to use a workaround. One thing that's commonly done is to use Twitter's search function, it would involve searching for all messages directed at Trump and then seeing which ones have a reply_id (the id of the tweet they are replying to) that is equal to a given Trump tweet id. The problem with this is that it is only able to look for replies to tweets that are max a week old. The second issue is that the amount of times that you can use the search function in the Twitter API is limited to a 100 queries an hour which is not ideal since it would take too long to get enough tweets to train our classifiers.\n",
    "\n",
    "Instead, we decided to do the following. We iterate over all of Trump's tweets, get the id of these tweets and then do a http request to the twitter page containing that tweet. Then we parse the page using BeautifulSoup and search for the attribute \"data-tweet-id\" in the HTML text. This attribute corresponds to an id of any tweet on that page which means that we can easily obtain the id of replies. Then, instead of using the search function in the Twitter API, we use a different method that can lookup tweet information given an id. This method is not limited to tweets that are more than 7 days old and has a higher rate limit. \n",
    "\n",
    "We are using the package Twarc and to use it we need authenticate it with keys and access tokens that can be obtained from the Twitter Dev website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twarc import Twarc\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key=\"zjwAsouRHgMzrMJxpWNxJtJYJ\"\n",
    "consumer_secret=\"uu2j3Do5fm266BPY2OiCajnIbUvWEiccgmfiNRZ9tGIfso1leN\"\n",
    "access_token=\"2758505181-7z1gXy1DgJDeGh1UqWwqiPeupQKmbapYPAeZ9QE\"\n",
    "access_token_secret=\"GjcjOwMzMwpjfFDW4an2qd1jwykYiYw0L5lb702PNHtYL\"\n",
    "\n",
    "\n",
    "f = open(\"authKeys.txt\", \"r\")\n",
    "\n",
    "keys=f.read()[2:].split(\":\")\n",
    "\n",
    "\n",
    "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#A list of lists for creating the dataframe\n",
    "L=[]\n",
    "\n",
    "#Column names for our dataframe containing replies\n",
    "indexList=[\"reply_id\",\"trump_id\",\"created_at\",\"coordinates\",\"favorite_count\",\"retweet_count\",\"geo\",\n",
    "                              \"place\",\"full_text\",\"location\",\"time_zone\",\"utc_offset\"]\n",
    "\n",
    "for i in range(len(indexList)):\n",
    "    L.append([])\n",
    "\n",
    "#Create empty dataframe\n",
    "replyDf=pd.DataFrame(columns=indexList)\n",
    "\n",
    "#Sort trump dataframe to get recent first\n",
    "df.sort_values(\"created_at\",inplace=True,ascending=False)\n",
    "\n",
    "#Adds the information from the reply tweet into our list of lists L\n",
    "def CreateReplyEntry(trumpId,replyId,replyTweet):\n",
    "    L[0].append(replyId)\n",
    "    L[1].append(trumpId)\n",
    "    for i in range(len(indexList)):\n",
    "        if(i>1):\n",
    "            if(i>8):\n",
    "                L[i].append(replyTweet[\"user\"][indexList[i]])\n",
    "            else:\n",
    "                L[i].append(replyTweet[indexList[i]])\n",
    "\n",
    "#For every tweet in given range, finds several replies\n",
    "#to that tweet (not guaranteed to find all replies)\n",
    "#start and end are indexes in trump tweets dataframe\n",
    "def ScrapeReplies(start,end):\n",
    "    #Iterate over every tweet\n",
    "    for i in range(start,end): #len(df) \n",
    "        if(i%100==0):\n",
    "            print(\"Tweet: \"+str(i))\n",
    "        #Set a limit so it doesn't take forever\n",
    "       # if(i>10):\n",
    "        #    break\n",
    "\n",
    "        #Get trump tweet and id\n",
    "        tweet=df.iloc[i]\n",
    "        tweetId=df.index[i]\n",
    "\n",
    "        url=\"https://twitter.com/realDonaldTrump/status/\"+tweetId\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        #Finds all div tags and if it has the corresponding id, add that id to a list\n",
    "        soup.find_all(\"div\")\n",
    "        divs = soup.find_all(\"div\")\n",
    "        ids=[]\n",
    "        for d in divs:\n",
    "            if d.has_attr('data-tweet-id'):\n",
    "                ids.append(d[\"data-tweet-id\"])  \n",
    "\n",
    "        for i in ids:\n",
    "            if(i!=tweetId): #dont want trump's tweet, just replies\n",
    "                reply=t.tweet(i)\n",
    "                CreateReplyEntry(tweetId,i,reply)   \n",
    "\n",
    "\n",
    "    for i in range(len(indexList)):\n",
    "        replyDf[indexList[i]]=L[i]\n",
    "\n",
    "    #replyDf.to_csv(\"data/replies/replies_\"+str(start)+\"_\"+str(end)+\".csv\", sep='\\t')\n",
    "    replyDf.to_pickle(\"data/replies/replies_\"+str(start)+\"_\"+str(end)+\".pkl\")\n",
    "    print(\"replies for tweets \"+str(start)+\" to \"+str(end)+\" saved\")\n",
    "    \n",
    "ScrapeReplies(2001,2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_pickle(\"data/replies/replies_801_2000.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergePickleFiles(fileNames):\n",
    "    dataframes=[]\n",
    "    for i in fileNames:\n",
    "        dataframes.append(pd.read_pickle(i))\n",
    "    return pd.concat(dataframes)\n",
    "\n",
    "#replies=MergePickleFiles([\"data/replies/replies_0_800.pkl\",\"data/replies/replies_801_2000.pkl\"])\n",
    "#replies.to_pickle(\"data/replies/replies_0_2000.pkl\")\n",
    "\n",
    "#len(pd.read_pickle(\"data/replies/replies_0_2000.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analyzing the data</h1><br>\n",
    "\n",
    "<h2>Attributes in the condensed Trump data</h2>\n",
    "\n",
    "What does the data look like ? In each json file, there is an array where each element represents\n",
    "a seperate tweet. In each array element, the following information can be found:<br>\n",
    "\n",
    "<ul>\n",
    "<li><b>created_at:</b> (string) the date the tweet was posted<br></li>\n",
    "<li><b>favourite_count:</b> (integer) represents the number of individual users that liked this post<br></li>\n",
    "<li><b>id_str:</b> (string) a unique string id for this tweet provided by the API<br></li>\n",
    "<li><b>in_reply_to_user_id_str:</b> (string) the string id of a tweet that this tweet is a reply to<br></li>\n",
    "<li><b>is_retweet:</b> (boolean) True if this tweet is a retweet of another tweet <br></li>\n",
    "<li><b>retweet_count:</b> (integer) an integer representing the amount of times this tweet was retweeted<br></li>\n",
    "<li><b>source:</b> (string/categorical) the type of device this tweet was posted from (for example a desktop or phone)<br></li>\n",
    "<li><b>text:</b> (string) the actual text from this tweet<br></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see all of the possible values of <b>source</b>, we simply use the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Twitter Web Client', 'TweetDeck', 'TwitLonger Beta', 'Facebook',\n",
       "       'Twitter for iPhone', 'Mobile Web (M5)', 'Twitter for Android',\n",
       "       'Instagram', 'Twitlonger', 'Vine - Make a Scene',\n",
       "       'Twitter for Websites', 'Twitter for BlackBerry',\n",
       "       'Neatly For BlackBerry 10', 'Periscope', 'Twitter QandA',\n",
       "       'Twitter Mirror for iPad', 'Twitter Ads', 'Twitter for iPad',\n",
       "       'Media Studio'], dtype=object)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"source\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>favourite_count</b> and <b>retweet_count</b> are both positive integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of what 1 entry may look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at                                               2009-05-04 18:54:25\n",
       "favorite_count                                                           202\n",
       "in_reply_to_user_id_str                                                 None\n",
       "is_retweet                                                             False\n",
       "retweet_count                                                            253\n",
       "source                                                    Twitter Web Client\n",
       "text                       Be sure to tune in and watch Donald Trump on L...\n",
       "Name: 1698308935, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important thing to be noted about twitter for those who are unfamiliar, a retweet is essentially where you take someone else's tweet and post that to your twitter feed where as a reply is a tweet that is directly aimed at an existing tweet. \n",
    "\n",
    "What we can see from the dataset above is that not all of the information we need is there. For example to do a proper sentiment analysis of people reacting to Trump, we need to look at the replies of these people. Also, we need to see what country those replies originated from. This can be done using the twitter API since the API calls contain more extensive information such as geolocation of the tweet's origin. \n",
    "\n",
    "If we take a look at the tweets themselves, we see that there are certain symbols and text that we can remove as they don't contribute to our clustering of topics. For example, a lot of tweets contain external http links. Also, twitter happens to encode the & symbol as the string &amp so these need to be converted. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computing statistical information</h2>\n",
    "\n",
    "Using the describe function below, we can see that there are 30192 tweets in our total dataset. Only two of the features can have these values computed because the rest are strings or booleans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30192.000000</td>\n",
       "      <td>30192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3385.386228</td>\n",
       "      <td>1363.948198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12319.745232</td>\n",
       "      <td>4813.511737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>773.750000</td>\n",
       "      <td>684.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>633253.000000</td>\n",
       "      <td>344806.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorite_count  retweet_count\n",
       "count    30192.000000   30192.000000\n",
       "mean      3385.386228    1363.948198\n",
       "std      12319.745232    4813.511737\n",
       "min          0.000000       0.000000\n",
       "25%         19.000000      15.000000\n",
       "50%         58.000000      74.000000\n",
       "75%        773.750000     684.250000\n",
       "max     633253.000000  344806.000000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucldV97/HPV0BCvYIiNUBEj5ykaqNGiqa5NAkNkNhX\n8SSa0Ju0h2p6tD1JT3N8YdMTUi2tJmlsOImkJhLR2CAhMXKSGBwR6w2BQRFEwRm5CCMwAzPcrzPz\nO3/sNcOeYYZ5ZpiZvff4fb9e+7XXXs+z1rPW7Jn9m/Ws9TxbEYGZmVkWpxS6AWZmVjocNMzMLDMH\nDTMzy8xBw8zMMnPQMDOzzBw0zMwsMwcNMzPLzEHDzMwyc9AwM7PM+he6Ad3t3HPPjVGjRhW6GWZm\nJWXFihU7ImJoR/v1uaAxatQoysvLC90MM7OSImlTlv18esrMzDJz0DAzs8wcNMzMLDMHDTMzy8xB\nw8zMMnPQMDOzzBw0zMwsMwcNM7MStnDNNqr3Huq14zlomJmVqMP1DXzhoRX88feX9toxHTTMzEpU\nRO55c+2BXjumg4aZmWXmoGFmZpk5aJiZWWYOGmZmlpmDhpmZZZYpaEg6W9J8SWslvS7pg5KGSCqT\nVJGeB+ftf7ukSknrJE3Iy79K0uq0baYkpfyBkh5J+UsljcorMyUdo0LSlO7ruplZ3xC9eKysI41v\nA7+OiPcBlwOvA9OARRExGliUXiPpEmAycCkwEbhXUr9UzyzgJmB0ekxM+VOBuoi4GLgHuDvVNQSY\nDlwNjAWm5wcnMzPrXR0GDUlnAR8F7geIiCMRsQuYBMxJu80BrkvpScDciDgcERuASmCspPOBMyPi\nxYgI4MFWZZrqmg+MS6OQCUBZRNRGRB1QxrFAY2ZmvSzLSONCoAb4oaSXJf1A0mnAsIjYmvbZBgxL\n6eHA5rzyW1Le8JRund+iTETUA7uBc05Ql5mZFUCWoNEf+AAwKyKuBPaTTkU1SSOH3jyt1oKkmyWV\nSyqvqakpVDPMzPq8LEFjC7AlIppubjKfXBDZnk45kZ6r0/YqYGRe+REpryqlW+e3KCOpP3AWsPME\ndbUQEfdFxJiIGDN06NAMXTIzs67oMGhExDZgs6T3pqxxwGvAAqBpNdMU4LGUXgBMTiuiLiQ34b0s\nncraI+maNF9xY6syTXVdDzyVRi8LgfGSBqcJ8PEpz8zMCqB/xv3+BnhY0qnAeuAvyAWceZKmApuA\nzwFExBpJ88gFlnrg1ohoSPXcAjwADAIeTw/ITbI/JKkSqCW3+oqIqJV0J7A87XdHRNR2sa9mZnaS\nMgWNiFgJjGlj07h29p8BzGgjvxy4rI38Q8AN7dQ1G5idpZ1mZu9IvTij7CvCzcxKVO7y6N7loGFm\nZpk5aJiZlagj9Y2554bGXjumg4aZWYl6cX3vrwty0DAzs8wcNMzMLDMHDTMzy8xBw8ysRBVgxa2D\nhpmZZeegYWZmmTlomJlZZg4aZmYlyrcRMTOzouagYWZmmTlomJmVKJ+eMjOzouagYWZmmTlomJlZ\nZg4aZmaWmYOGmVmJUgHuPuWgYWZmmTlomJlZZpmChqSNklZLWimpPOUNkVQmqSI9D87b/3ZJlZLW\nSZqQl39VqqdS0kwpt8pY0kBJj6T8pZJG5ZWZko5RIWlKd3XczMw6rzMjjY9HxBURMSa9ngYsiojR\nwKL0GkmXAJOBS4GJwL2S+qUys4CbgNHpMTHlTwXqIuJi4B7g7lTXEGA6cDUwFpieH5zMzN7Jguj1\nY57M6alJwJyUngNcl5c/NyIOR8QGoBIYK+l84MyIeDEiAniwVZmmuuYD49IoZAJQFhG1EVEHlHEs\n0JiZWS/LGjQCeFLSCkk3p7xhEbE1pbcBw1J6OLA5r+yWlDc8pVvntygTEfXAbuCcE9RlZmYF0D/j\nfh+OiCpJ5wFlktbmb4yIkNT746QkBbKbAd7znvcUqhlmZn1eppFGRFSl52rgUXLzC9vTKSfSc3Xa\nvQoYmVd8RMqrSunW+S3KSOoPnAXsPEFdrdt3X0SMiYgxQ4cOzdIlM7OSV5TXaUg6TdIZTWlgPPAq\nsABoWs00BXgspRcAk9OKqAvJTXgvS6ey9ki6Js1X3NiqTFNd1wNPpXmPhcB4SYPTBPj4lGdmZgWQ\n5fTUMODRtDq2P/AfEfFrScuBeZKmApuAzwFExBpJ84DXgHrg1ohoSHXdAjwADAIeTw+A+4GHJFUC\nteRWXxERtZLuBJan/e6IiNqT6K+ZmZ2EDoNGRKwHLm8jfycwrp0yM4AZbeSXA5e1kX8IuKGdumYD\nsztqp5mZ9TxfEW5mZpk5aJiZWWYOGmZmlpmDhpmZZeagYWZWqnr/Mg0HDTMzy85Bw8zMMnPQMDMr\nVQW445+DhpmZZeagYWZmmTlomJlZZg4aZmalyktuzcysmDlomJlZZg4aZmaWmYOGmZll5qBhZmaZ\nOWiYmVlmDhpmZpaZg4aZWYkqwGUaDhpmZpadg4aZmWWWOWhI6ifpZUm/SK+HSCqTVJGeB+fte7uk\nSknrJE3Iy79K0uq0baYkpfyBkh5J+UsljcorMyUdo0LSlO7otJmZdU1nRhpfBF7Pez0NWBQRo4FF\n6TWSLgEmA5cCE4F7JfVLZWYBNwGj02Niyp8K1EXExcA9wN2priHAdOBqYCwwPT84mZlZ78oUNCSN\nAK4FfpCXPQmYk9JzgOvy8udGxOGI2ABUAmMlnQ+cGREvRkQAD7Yq01TXfGBcGoVMAMoiojYi6oAy\njgUaMzPrZVlHGv8G3AY05uUNi4itKb0NGJbSw4HNefttSXnDU7p1fosyEVEP7AbOOUFdZmZWAB0G\nDUl/AFRHxIr29kkjhwJ88WCOpJsllUsqr6mpKVQzzMz6vCwjjQ8BfyhpIzAX+ISkHwHb0ykn0nN1\n2r8KGJlXfkTKq0rp1vktykjqD5wF7DxBXS1ExH0RMSYixgwdOjRDl8zMSl9aS9SrOgwaEXF7RIyI\niFHkJrifiog/BRYATauZpgCPpfQCYHJaEXUhuQnvZelU1h5J16T5ihtblWmq6/p0jAAWAuMlDU4T\n4ONTnpmZFUD/kyh7FzBP0lRgE/A5gIhYI2ke8BpQD9waEQ2pzC3AA8Ag4PH0ALgfeEhSJVBLLjgR\nEbWS7gSWp/3uiIjak2izmZmdhE4FjYh4Gng6pXcC49rZbwYwo438cuCyNvIPATe0U9dsYHZn2mlm\nZj3DV4SbmVlmDhpmZiUqN/Xbuxw0zMwsMwcNMzPLzEHDzKxEFeV1GmZmZk0cNMzMLDMHDTMzy8xB\nw8zMMnPQMDPrA97edZCqXQd7/Dgnc+8pMzMrEr9711MAbLzr2h49jkcaZmYlqvcX3DpomJmVrEJ8\n852DhpmZZeagYWZmmTlomJlZZg4aZmaWmYOGmZll5qBhZmaZOWiYmZUoX6dhZmZFzUHDzMwyc9Aw\nM7PMOgwakt4laZmkVyStkfSPKX+IpDJJFel5cF6Z2yVVSlonaUJe/lWSVqdtM5W+q1DSQEmPpPyl\nkkbllZmSjlEhaUp3dt7MzDony0jjMPCJiLgcuAKYKOkaYBqwKCJGA4vSayRdAkwGLgUmAvdK6pfq\nmgXcBIxOj4kpfypQFxEXA/cAd6e6hgDTgauBscD0/OBkZma9q8OgETn70ssB6RHAJGBOyp8DXJfS\nk4C5EXE4IjYAlcBYSecDZ0bEixERwIOtyjTVNR8Yl0YhE4CyiKiNiDqgjGOBxszMelmmOQ1J/SSt\nBKrJfYgvBYZFxNa0yzZgWEoPBzbnFd+S8oandOv8FmUioh7YDZxzgrpat+9mSeWSymtqarJ0ycys\nYCqr9/KjFzcVuhldkiloRERDRFwBjCA3aris1fagMHfpbTr+fRExJiLGDB06tFDNMDPL5NMzn+Mf\nfv7qSdejAlyo0anVUxGxC1hM7hTR9nTKifRcnXarAkbmFRuR8qpSunV+izKS+gNnATtPUJeZWck6\nUt9Y6CZ0WZbVU0MlnZ3Sg4BPAmuBBUDTaqYpwGMpvQCYnFZEXUhuwntZOpW1R9I1ab7ixlZlmuq6\nHngqjV4WAuMlDU4T4ONTnpmZFUCW7wg/H5iTVkCdAsyLiF9IWgLMkzQV2AR8DiAi1kiaB7wG1AO3\nRkRDqusW4AFgEPB4egDcDzwkqRKoJbf6ioiolXQnsDztd0dE1J5Mh83MrOs6DBoRsQq4so38ncC4\ndsrMAGa0kV8OXNZG/iHghnbqmg3M7qidZmbW83xFuJmZZeagYWZmmTlomJlZZg4aZmYlSgX4Rg0H\nDTMzy8xBw8zMMnPQMDOzzBw0zMwsMwcNM7MSFQW4T6yDhplZgS1eV83itdUd71gEstx7yszMetBf\n/DB3e72Nd11b4JZ0zCMNM7MS5es0zMysqDlomJlZZg4aZmaWmYOGmZll5qBhZlaifJ2GmZkVNQcN\nM7MS5SW3ZmZW1Bw0zMwsMwcNMzPLrMOgIWmkpMWSXpO0RtIXU/4QSWWSKtLz4Lwyt0uqlLRO0oS8\n/KskrU7bZkpSyh8o6ZGUv1TSqLwyU9IxKiRN6c7Om5lZ52QZadQDfxcRlwDXALdKugSYBiyKiNHA\novSatG0ycCkwEbhXUr9U1yzgJmB0ekxM+VOBuoi4GLgHuDvVNQSYDlwNjAWm5wcnMzPrXR0GjYjY\nGhEvpfRe4HVgODAJmJN2mwNcl9KTgLkRcTgiNgCVwFhJ5wNnRsSLERHAg63KNNU1HxiXRiETgLKI\nqI2IOqCMY4HGzMx6WafmNNJpoyuBpcCwiNiaNm0DhqX0cGBzXrEtKW94SrfOb1EmIuqB3cA5J6ir\ndbtullQuqbympqYzXTIzs07IHDQknQ78FPhSROzJ35ZGDr1/aeKx498XEWMiYszQoUML1Qwzs16l\n3r9MI1vQkDSAXMB4OCJ+lrK3p1NOpOemr52qAkbmFR+R8qpSunV+izKS+gNnATtPUJeZmRVAltVT\nAu4HXo+Ib+VtWgA0rWaaAjyWlz85rYi6kNyE97J0KmuPpGtSnTe2KtNU1/XAU2n0shAYL2lwmgAf\nn/LMzKwAsnzd64eAPwNWS1qZ8v4euAuYJ2kqsAn4HEBErJE0D3iN3MqrWyOiIZW7BXgAGAQ8nh6Q\nC0oPSaoEasmtviIiaiXdCSxP+90REbVd7KuZmZ2kDoNGRDwH7d7gZFw7ZWYAM9rILwcuayP/EHBD\nO3XNBmZ31E4zM+t5viLczMwyc9AwM7PMHDTMzCwzBw0zsxJVgMs0HDTMzCw7Bw0zM8vMQcPMzDJz\n0DAzs8wcNMzMLDMHDTMzy8xBw8zMMnPQMDMrVcX6fRpmZmbgoGFmZp3goGFmZpk5aJiZWWYOGmZm\nlpmDhplZqYreP6SDhplZDzt0tIHdB4+eVB1b6g7w2MqqbmpR13X4HeFmZnZyPj3zWdbX7GfjXdd2\nuY4P370YgCtGns0F55yWy/R1GmZmfc/6mv3dVlf+iOXXr27rtnqzctAwMyshkTeP8eCSTb1+/A6D\nhqTZkqolvZqXN0RSmaSK9Dw4b9vtkiolrZM0IS//Kkmr07aZkpTyB0p6JOUvlTQqr8yUdIwKSVO6\nq9NmZqXkwJH65nQB5r5byDLSeACY2CpvGrAoIkYDi9JrJF0CTAYuTWXuldQvlZkF3ASMTo+mOqcC\ndRFxMXAPcHeqawgwHbgaGAtMzw9OZmbvFH8375XmdGMUNmx0GDQi4hmgtlX2JGBOSs8BrsvLnxsR\nhyNiA1AJjJV0PnBmRLwYEQE82KpMU13zgXFpFDIBKIuI2oioA8o4PniZmfV5a97eU+gmNOvqnMaw\niNia0tuAYSk9HNict9+WlDc8pVvntygTEfXAbuCcE9T1jvPNhetYuKb3J7zMzFo76YnwNHIo6HhJ\n0s2SyiWV19TUFLIpPeI7iyv5wkMrCt0MM7MuB43t6ZQT6bk65VcBI/P2G5HyqlK6dX6LMpL6A2cB\nO09Q13Ei4r6IGBMRY4YOHdrFLpmZ9a76hkbqGxo7VaYAl2a00NWgsQBoWs00BXgsL39yWhF1IbkJ\n72XpVNYeSdek+YobW5Vpqut64Kk0elkIjJc0OE2Aj095ZmZ9wr8/s55frNra8Y5FpMMrwiX9GPgY\ncK6kLeRWNN0FzJM0FdgEfA4gItZImge8BtQDt0ZEQ6rqFnIrsQYBj6cHwP3AQ5IqyU24T0511Uq6\nE1ie9rsjIlpPyJuZlay3dx1k6OkDm18/trKKrbsPUVV3kDuvu6zNMi+9tYvfHn4W/fsV5jK7DoNG\nRPxRO5vGtbP/DGBGG/nlwHE/hYg4BNzQTl2zgdkdtdHMrFTd9tNVzekvzl3ZnG4vaNz5i9fYue8w\nt018X4+3rS2+IryILFyzjecqdhS6GWZWZKLVWqPyjXVEga7X8A0Li0jTCqmTuamZmZUOdXFWe9nG\nWhoLtGbVIw0zswLJMlh44PkNbK49eFz+oaMNbezd8xw0zMyKVM3ew3zt/73W5rZLpxdmMamDRpEr\n1HlLM+t5HZ2e+qsfFd9FvQ4aRW7BK28XuglmVgARwYpNdYVuxnEcNIrczn1HCt0EMyuA35mxqNBN\naJODRpHr6uqKzrrl4RVF8f3DZpazY9/hQjehTQ4aRWhe+WY+9e1ne/WYv1q9rcWFRV3xQuUORk37\nJZt2dt9XW5r1ZYePdu6+U8XA12kUodvmH7tCtNA3J+uM+S/l7n6/fGPdsS++N7N2/WTFlo53KjIe\naVi384ove6d7cMlGtu85VOhm9AgHjSKn3prU6AZK4yKHDHsn21x7gK8+toar/7ntieydRTpXkZVP\nT1m3KaH4ZtYjVmyqPeEy2S11B/jef77Ziy3qfg4a1v1OMNTYe+goKzbV8bH3ntd77THrJZ+dteSE\n2z989+JeaknP8empAinfWMvh+o7vHVNK/703NbX1HTnzfXHuSv78h8vZtrtvnu/tTs9W1HDwSAP7\nDtcz/bFXOXikMPcasq57oXIHRzv5zXzFzkGjACqr93H995ZwRzv3lClFew8dzbQSZH3NPgAOFuhm\na6Vifc0+/uz+Zfz9o6uZ9XQlc5Zs4sElGwvdrHekz//7Eua3+t2ub2jkhcodNDYGi9dWc+hoA99+\nsuK4sn/8g6UseXNnbzW1V/j0VAHsPpi7yvv1rXs63LdUBhqV1fua0ydaPHVKGjo19PB9nX+x6m32\nH67n87/znh49Tk/Ze6geyP1czzsz981uhboVdl/161e38lc/eglo++sIIoI1b+9h6YZalm6o5fqr\nRjRv+87iSv7tyQqu/e3z+eXqrVx07mms39H29Uk3zl7WMx0oEAeNgsh9cL4TPwROOSWtsOrhZbl/\n/R8vA5Rs0Gg6LXmiU33WsVseXsGho43M/vPfOW5bU8Boz4JX3m7zgtfGxmB9TS5ALN+Y+wbq9gJG\nX+SgUQCdmqc4iUmNhsbgSH0jg07t1+U6ssq6NDjFjKILmHsPHaW+IRh82qmFbgpwbPky0Ok1zG/t\nPEBDBBee23cvsKxvaORnL1fx2Q+MoN8p7f/u/Wr1ti4fI3/0nO+iv/9Vc7p6b2kvn+0Kz2kUUE9/\nbt7+s1X81ld/3cNHOd6J+tV0eqqxyC4AHDtjEVfeWdZj9b/29h4Wrun8B1j+jynr/w8f/cZiPv7N\npzt9rFLywAsbuW3+KuYuf6tb6nu+cgcbduxn4ZptlKfRQ9lr21vss7n2AM9X+uuYPdLopPKNtWzc\neaDF+c3Oav7b7+EPznnlxXuLgmILGj09Mf/pmbl7iWX9Kt+2AkSR/cgKqu5Abl6wdt8R3vd/HueP\nx17A+37zDP7rb57BFSPP7nR9f/KDpS1ef/Cic1i7bW+LvI98fTG3fOy/dL3RfYRHGp10/feW8OWf\nvNLpco2NQXW6rUDTf9tZPgOKdSK8sTFYsam2zW1ZJsJPtM/m2gNdatN1332ebyxc26WyxSqC4v0l\nSNZu29PpG1XuOnDkpG6zsfvgUQD+teyN3JzF8xu47aeruO67zzfPlx04Ut+8/0tv1bF2W8cLT5os\nWd/2iqd7ny7tC/O6Q0kEDUkTJa2TVClpWqHb0xXff3Y9Y/95ERt37D82yRm5X+z2JoU31x5oDjQn\no636f/5yFU+vq+5UPXX7jzT/4d3/3AY+O2sJz1bUHH+8vHD4xva9bKk7FgSazj+3N9J4Ys02PvL1\nxcedGshi5eZdfHdxtj/qiu17qaze2/GOnVDf0Jjp2pssWtRT5COM+WlE+8SaE79nf/vISqb9NHcz\nzrEzFrW4zcYVdzzBqGm/pHZ/y++P2bnvMN/7zzdbLHm9p+wNfvRi+6elvvDQCr7zVAWf/NYzzXmf\nufcFJv7bs3z912t5rmKHv9zsJBR90JDUD/gu8CngEuCPJF3SU8frqdt6P5/Wam/cuZ/7nlkP5IbY\nl3x1ITMXVbZZ5iNfX8zMp9re1tAYfOXR1WxoY9XG3kNHm6+HAHj05Sou/8cnqM+7yOhLj+QusuuM\nz8zK/eEBPPl67gPivmfWs+fQ0XbLjL/nmRZXwW7dfRBofyJ8XTol8MrmXR2258CRemYuqmjRr6w+\nec8z/P63njnug37XgSOs3rK7xb4/XvYWo6b9krr9R/jgvyxqdzTzR99/kff+Q24Oqb6hkUPtnPLa\nXHuAHz6/4YTta7qyODj27Y33lL0BwD//6nU+dNdT7D3Bz70z1ry9u93/+hsag8aTWLWw4JW3+cs5\n5UDu93Du8s0AHGn1nu06kOvLwjXbeKFyBweO1LNhx36u+qcnuevxtXz5J6/wpz9Yyj1lb/DtRcdf\nD5Hvide2880n3qBq18Hjtt379Jv86f1L+Z8/frnLfXqnK4U5jbFAZUSsB5A0F5gEdPuVcX/4nedY\ntWU393z+cq67Yjj/e/4qNuzYz9ybryECTu1/LMb+/OUqrrtyOPNXbGHnvsNcdcFgBvQ7hUNHG7j6\nonOa95u77C2m/Wx18+sHXtjI0+ty/51vqcv9Uv/fpyo45/SOV+2MmvZLRg4ZxG8M6M/IIYN48vVq\nnq3YwTO3fRyg+Y/7Y994mp15/7H9r3m502nrtu/l0nef1eLDbH3NPgYOaLm6atWWXRxtaOSqC4YQ\nETQ0Bht37m8RoJZuyJ2aerZiB7c+/BJfHv/e5m1PrNnOn1x9AfsPHzs9sGxDLbsPHmVH+ibChsZG\nduw7zOkD+1Oz93DzVbMD0s/4O4srufXjFzOgn9hzqJ4z3tWf6r2HWbdtDx9/73ls2LGfG763hJ37\nj/Ct9GHaJP+GcPUNjfTvdwoHjzSwaO12Lh9xdvM1EAAXf+XxFmWvuCM3Gf4fN13N6PPOoHrvIW5P\n79+cJRvZuvsQ3138Jp9433l84D2D2br7EMs21DLxst9k+ca65vfp1P6ncKS+kZ/+jw+2uLXEtt2H\n+MjXc0H0939rGK9v3cP7R5zN3OVvcem7z2Lc+87jaOOxD9T8a3mONDTyt4+s5NGXc1+W9dtfe4IX\npn2CIaedyncXVzJ57Hs4feCxP+kj9Y00RjCg3ynNZ7j2Hq7nhcodfGj0uZz5rgEAXDvzOeDYfMvR\nhkb+bt4rTLri3UxNH/irvjaeQQP68d8fWM6+w/U8/JdXc2q/U+h3itr8B6CxMTjS0Nj84fylucc+\npGtOsOLo9ry/ldaeq9zBc56ILjgV+22sJV0PTIyIv0yv/wy4OiL+uq39x4wZE+Xl5Z0+zls7D/DR\nb3TuvjDDzx7U5n8zZqXitFP7sT/dnmTYmQOpO3CUI/V967YXfdHGu65l1LRftrutKyStiIgxHe1X\n9KenspB0s6RySeU1NcefY89ixOBBzems69vPO3MgA/odP0t58XmnA7T4r6+UndYL13lY7+t/ipoD\nBsD7R5zdqYBRLL8XF5zzGy1eX/v+85vTQ047lUFpJN3W3/XPb/0Q37j+/cz6kw/wmSuH8/kxI3n9\njonM+8IHWXvnRCpmfIpJV7y73WNfnlZqDRpw/M/iI6PPbdEWgD94//n81e+1XIHV1mcIwDdvuLzN\n/HPStUT/dN1lx237898d1W5bu0spjDQ+CHwtIiak17cDRMS/tLV/V0caZmbvZH1ppLEcGC3pQkmn\nApOBBQVuk5nZO1LRnz+JiHpJfw0sBPoBsyNiTYGbZWb2jlT0QQMgIn4F/KrDHc3MrEeVwukpMzMr\nEg4aZmaWmYOGmZll5qBhZmaZOWiYmVlmRX9xX2dJqgE2nUQV5wJ94QY37kfx6St96Sv9gL7Tl+7o\nxwURMbSjnfpc0DhZksqzXBVZ7NyP4tNX+tJX+gF9py+92Q+fnjIzs8wcNMzMLDMHjePdV+gGdBP3\no/j0lb70lX5A3+lLr/XDcxpmZpaZRxpmZpaZg0YiaaKkdZIqJU0rdHvaImmjpNWSVkoqT3lDJJVJ\nqkjPg/P2vz31Z52kCXn5V6V6KiXNlNT2t8B0b9tnS6qW9GpeXre1XdJASY+k/KWSRvViP74mqSq9\nLyslfboE+jFS0mJJr0laI+mLKb8U35P2+lJS74ukd0laJumV1I9/TPnF9Z5ExDv+Qe6W628CFwGn\nAq8AlxS6XW20cyNwbqu8rwPTUnoacHdKX5L6MRC4MPWvX9q2DLgGEPA48KleaPtHgQ8Ar/ZE24Fb\ngO+l9GTgkV7sx9eAL7exbzH343zgAyl9BvBGam8pvift9aWk3pd0zNNTegCwNLWlqN4TjzRyxgKV\nEbE+Io4Ac4FJBW5TVpOAOSk9B7guL39uRByOiA1AJTBW0vnAmRHxYuR+cx7MK9NjIuIZoLYH255f\n13xgXE+MoNrpR3uKuR9bI+KllN4LvA4MpzTfk/b60p6i7Evk7EsvB6RHUGTviYNGznBgc97rLZz4\nl65QAnhS0gpJN6e8YRGxNaW3AcNSur0+DU/p1vmF0J1tby4TEfXAbuCcnml2m/5G0qp0+qrp9EFJ\n9COdoriS3H+2Jf2etOoLlNj7IqmfpJVANVAWEUX3njholJYPR8QVwKeAWyV9NH9j+q+iJJfDlXLb\ngVnkTm1eAWwF/rWwzclO0unAT4EvRcSe/G2l9p600ZeSe18ioiH9jY8gN2q4rNX2gr8nDho5VcDI\nvNcjUl49NA9AAAABnklEQVRRiYiq9FwNPErutNr2NBwlPVen3dvrU1VKt84vhO5se3MZSf2Bs4Cd\nPdbyPBGxPf2xNwLfJ/e+tGhTq/YWRT8kDSD3IftwRPwsZZfke9JWX0r1fUlt3wUsBiZSZO+Jg0bO\ncmC0pAslnUpugmhBgdvUgqTTJJ3RlAbGA6+Sa+eUtNsU4LGUXgBMTqslLgRGA8vSMHePpGvSucwb\n88r0tu5se35d1wNPpf/KelzTH3Ty38i9L01tKsp+pOPeD7weEd/K21Ry70l7fSm190XSUElnp/Qg\n4JPAWortPenKLH9ffACfJrfq4k3gK4VuTxvtu4jcSolXgDVNbSR3PnIRUAE8CQzJK/OV1J915K2Q\nAsaQ+wN6E/gO6SLPHm7/j8mdIjhK7hzr1O5sO/Au4CfkJgOXARf1Yj8eAlYDq9If5fkl0I8PkzvN\nsQpYmR6fLtH3pL2+lNT7ArwfeDm191Xgqym/qN4TXxFuZmaZ+fSUmZll5qBhZmaZOWiYmVlmDhpm\nZpaZg4aZmWXmoGFmZpk5aJiZWWYOGmZmltn/Bx14W1p2x9ZsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x247da833c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmaZOWiYmVlm/x9+h0wMkTHnyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x247d5834eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(df[\"favorite_count\"]))\n",
    "plt.show()\n",
    "plt.plot(list(df[\"retweet_count\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking for missing values</h2>\n",
    "\n",
    "We will now check to see if there are potentially any values missing at all. Note that we don't consider a value of None in <b>in_reply_to_user_id_str</b> to be a missing value as it's acceptable for a tweet to not reply to another. We make a copy of our original dataframe, drop the in_reply_to_user_id_str (because pandas replcae the value None with a null value in this case) and then do a query to return all entries with some form of missing value. As we can see, we get no entries in this case so all of the values are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [created_at, favorite_count, is_retweet, retweet_count, source, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNull=df.copy()\n",
    "dfNull=dfNull.drop(\"in_reply_to_user_id_str\",axis=1)\n",
    "dfNull[dfNull.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Correlations between features</h2>\n",
    "\n",
    "Next we want to analyze the correlations between the different fields. It doesn't make sense to look at correlations between string fields and the rest as the strings can take on a large range of values that aren't repeated often. However we can convert the categorical strings into integers as they occur frequently. We create a copy of the dataframe and then create a dictionary to have a mapping from a <b>source</b> value to an integer. Then we alter all of the rows in this datafram to have these integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfCorr=df.copy()\n",
    "\n",
    "keys=dfCorr[\"source\"].unique()\n",
    "values=list(range(len(keys)))\n",
    "dictionary = dict(zip(keys, values))\n",
    "\n",
    "for i in range(len(dfCorr)):    \n",
    "    s=dfCorr.iloc[i][\"source\"]\n",
    "    dfCorr.iloc[i, dfCorr.columns.get_loc('source')] = int(dictionary.get(s))\n",
    "    \n",
    "dfCorr[\"source\"] = dfCorr[\"source\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at                 datetime64[ns]\n",
       "favorite_count                      int64\n",
       "in_reply_to_user_id_str            object\n",
       "is_retweet                           bool\n",
       "retweet_count                       int64\n",
       "source                              int64\n",
       "text                               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCorr.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a correlation matrix between all of the integer values as well as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>favorite_count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021752</td>\n",
       "      <td>0.916265</td>\n",
       "      <td>0.134390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_retweet</th>\n",
       "      <td>-0.021752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084379</td>\n",
       "      <td>-0.002959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retweet_count</th>\n",
       "      <td>0.916265</td>\n",
       "      <td>0.084379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>0.134390</td>\n",
       "      <td>-0.002959</td>\n",
       "      <td>0.100975</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                favorite_count  is_retweet  retweet_count    source\n",
       "favorite_count        1.000000   -0.021752       0.916265  0.134390\n",
       "is_retweet           -0.021752    1.000000       0.084379 -0.002959\n",
       "retweet_count         0.916265    0.084379       1.000000  0.100975\n",
       "source                0.134390   -0.002959       0.100975  1.000000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrMatr=dfCorr.corr(method='pearson', min_periods=1)\n",
    "corrMatr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRPhAIMIHAhE+EIjwgUD/Af81y4on+EGqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x247d971d320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(corrMatr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret the matrix, yellow is for 100% correlation (when a variable correlates to itself), the more darker colours represent less correlation and the green one show that there is a relatively high correlation (>90%). What we see is that for Trump's tweets, the <b>favorite_count</b> and <b>retweet_count</b> are highly correlated. The correlations between the other variables are quite low (from -0.021752 to 0.134390)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Roadmap to Milestone 3</h1>\n",
    "\n",
    "This section contains all the tasks that we intend to complete for the 3rd milestone.\n",
    "\n",
    "\n",
    "<h3>Classify users' reaction to a topic by sentiment and country.</h3>\n",
    "<h3>Plot a world map for each topic</h3>\n",
    "\n",
    "\n",
    "<h3>Plan for presentation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classification of Trump's tweets by topic</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering of tweets will be implemented via topic modeling, more specifically via Latent Dirichlet Allocation (in short LDA). In LDA the documents of a corpus are generated according to a mixture of (dirichlet) word distributions over a vocabulary of fixed size. Guiding intuition, such word distributions are named \"topics\". Each document is characterized by a per-document (dirichlet) topic distribution and a total number of words N. Each word of the document is generated by first sampling a topic assignment out of the per-document distribution and then by sampling a word out of the word distribution. The machine learning task is to backtrack this process to \"infer\" the latent topic distribution of the document. Given the model and the per-document distribution, a corpus can be fully characterized (up to words order, since documents are bag-of-words). This entails that if the number of topics K is s.t. K << D, where D is the length of the dictionary, then under LDA every document has a more succint representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from stop_words import get_stop_words\n",
    "from gensim import corpora, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%pylab inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing has been performed iteratively: at each step, the output of simple functions and tokenization was analyzed seeking for the most occurring incorrect tokens. After determining the cause of the incorrect tokenization, a rule was written to fix it. This process was repeated until, after a thorough inspection, most of the tokens were meaningful. Particular care was devoted to this phase since the performance of clustering algorithms generally depends on the underlying data. The pre-processing includes: shifting to lower case, stripping links, dates and time. Punctuation was ignored except for \".\" and \"'\" since many proper names include these symbols (single or multiple periods are still ignored however). Other accepted symbols are \"@\" and \"#\" at the begin of a word. Stopwords are stripped out. Finally, stemming was applied, even though we found out some cases of ambiguity and reduced readability. We decided to deploy stemming anyway since the various verb conjugations such as \"said\" and \"say\" were a far bigger issue than some small inconvenience. Moreover, readability was maintained by keeping track of both processed and unprocessed tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process a single tweet\n",
    "def preProcess_procedure(tweet):\n",
    "    original = tweet\n",
    "    tweet = re.sub(r'([a-z]+)\\.([A-Z].+)', '\\1 \\2', tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'(\\d+[:\\/,\\.])+\\d+ *([ap]\\.?m\\.?)?', '', tweet)\n",
    "    tokenizer = RegexpTokenizer(r'[a-z_@#][a-z0-9_\\'\\.]+[a-z0-9_]')\n",
    "    tweet = tokenizer.tokenize(tweet)\n",
    "    stopwords = get_stop_words('en')\n",
    "    stopwords.append('amp')\n",
    "    p_stemmer = PorterStemmer()\n",
    "    tweet = [i for i in tweet if not i in stopwords]\n",
    "    tweet = [p_stemmer.stem(i) for i in tweet]\n",
    "    #print(original, \"=>\", tweet)\n",
    "    return tweet\n",
    "    \n",
    "# Pre-process a list of tweets\n",
    "def preProcess(tweets, ratio=0.8):\n",
    "    tweets.index = range(len(tweets))\n",
    "    indices = np.random.permutation(tweets.index)\n",
    "    train_len = int(len(tweets) * ratio)\n",
    "    train_indices = indices[:train_len]\n",
    "    test_indices = indices[train_len:]\n",
    "    orig_test = tweets[test_indices]\n",
    "    tweets = tweets.map(preProcess_procedure)\n",
    "    dictionary = corpora.Dictionary(tweets)\n",
    "    train = [dictionary.doc2bow(tweets[tweet]) for tweet in train_indices]\n",
    "    test = [dictionary.doc2bow(tweets[tweet]) for tweet in test_indices]\n",
    "    return train, test, orig_test, dictionary\n",
    "    \n",
    "train, ltest, orig_test, dictionary = preProcess(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right after feature pre-processing, a crucial step in clustering is determining the number of clusters. We started with a non-small number of topics (k = 100) attempting to first overfit the model to the training set (but still keeping a reasonable amount of topics for manual inspection) and then to progressively reduce the number of topics to increase performance. The goodness of fit was measured by first splitting in training and testing samples, inferring a test tweet's most probable topic and then assigning the tweet to that topic (hard clustering). However, this method seemed to be slow since every model seemed to derive small topics of approximately the same size (10 ~ 80 tweets each, where the biggest topic was 4% of the whole dataset). While selecting the number of clusters just so that the dataset would be nicely partitioned in bigger chunks was tempting, we were not sure whether a small cluster could still have a great impact in clustering. To this aim, many of the 100 topics were inspected and we found out that some topics were fairly similar (for example all topics addressing Ted Cruz were divided in several topics). \n",
    "\n",
    "At this point, our aim became minimizing the \"uncertainty\" of the per-tweet topic distributions (i.e. by having higher maxima). In order to do so, recall that in LDA a test sample document of D features is reduced to a K-vector in the K-topic space. We had the idea of computing the silhouette function in this space to improve goodness of fit. We decided to implement that using centroids (the average point of each cluster) and euclidian distance. Another test that would be interesting to make is to use the total variation distance since every point in the topic space is a probability distribution over K topics. A completely different approach that was implemented was to set the topic assignment zi as the center of the cluster. The total variation distance between a tweet and all zi is then simply 1 - di, where di is the i-th component of the tweet K-vector. This approach was not thoroghly tested but it seemed to produce similar results. As you may note below, the maximum silhouette value was achieved for k = 2. This behavior is certainly suspicious. Nonetheless, the resulting clusters seems to be of some use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computing silhouette in a K-dimensional topic space, where each document is reduced to a K-vector. Note that documents are\n",
    "# hard assigned to the topic with the highest probability. The centroids are computed as the average point of the cluster.\n",
    "\n",
    "from collections import defaultdict\n",
    "\"\"\"\n",
    "def silhouette(lda, tweet):\n",
    "    kvector = [x[1] for x in sorted(lda[tweet], key=lambda tup: tup[1], reverse=True)]\n",
    "    if (len(kvector) < 2):\n",
    "        return 1\n",
    "    neigh_dist = 1 - kvector[1]\n",
    "    same_dist = 1 - kvector[0]\n",
    "    return (neigh_dist - same_dist) / neigh_dist\n",
    "\"\"\"\n",
    "\n",
    "def silhouette(other, same):\n",
    "    return (other - same) / max(other, same)\n",
    "\n",
    "# Given a model, infer and assign a topic to every tweet\n",
    "def buildHardClusters(lda, ltest):\n",
    "    docs = [lda[tweet] for tweet in ltest if len(tweet) > 0]\n",
    "    clusters = [max(doc, key=lambda tup: tup[1]) for doc in docs]\n",
    "    dfTest = pd.DataFrame(columns=['Topic', 'Document'])\n",
    "    dfTest['Topic'] = [c[0] for c in clusters]\n",
    "    dfTest['Document'] = docs\n",
    "    return dfTest\n",
    "\n",
    "# From a cluster of tweets, compute the average point\n",
    "def buildCentroid(cluster):\n",
    "    dic = defaultdict(float)\n",
    "    for doc in cluster['Document']:\n",
    "        for comp in doc:\n",
    "            dic[comp[0]] += comp[1]\n",
    "    return [(t, p / len(cluster)) for t, p in dic.items()]\n",
    "\n",
    "# Difference of two vectors. We had to implement this since\n",
    "# zero entries are not stored in the vectors to save space\n",
    "def diff(doc1, doc2):\n",
    "    d = defaultdict(float)\n",
    "    for comp in doc1:\n",
    "        d[comp[0]] = comp[1]\n",
    "    for comp in doc2:\n",
    "        d[comp[0]] -= comp[1]\n",
    "    tot = 0\n",
    "    for k, v in d.items():\n",
    "        tot += v**2\n",
    "    return np.sqrt(tot)\n",
    "    \n",
    "def compute_silhouette(tweet, centroids):\n",
    "    same_dist = diff(tweet['Document'], centroids[tweet['Topic']]) \n",
    "    # Find nearest neighbor\n",
    "    neigh_dist = 999\n",
    "    for i in range(len(centroids)):\n",
    "        if i == tweet['Topic']:\n",
    "            continue\n",
    "        dist = diff(tweet['Document'], centroids[i])\n",
    "        if dist < neigh_dist:\n",
    "            neigh_dist = dist\n",
    "    return silhouette(neigh_dist, same_dist)\n",
    "\n",
    "# Grid Search method to determine k by maximizing the silhouette function.\n",
    "def grid_search_k(train, ltest, dictionary, start_k=2, lim=100):\n",
    "    res = pd.Series(index=range(start_k, lim + 1))\n",
    "    for k in range(start_k, lim + 1):\n",
    "        alda = models.ldamodel.LdaModel(train, num_topics=k, id2word = dictionary, passes=20)\n",
    "        dfTest = buildHardClusters(alda, ltest)\n",
    "        centroids = dfTest.groupby('Topic').apply(buildCentroid)\n",
    "        # Compute Average Silhouette\n",
    "        tot = 0\n",
    "        part_sil = dfTest.apply(compute_silhouette, args=(centroids,), axis=1)\n",
    "        sil = sum(part_sil) / len(dfTest)\n",
    "        print(\"k =\", k, \",\", \"silhouette =\", sil)\n",
    "        res[k] = sil\n",
    "    return res\n",
    "\n",
    "gsk = grid_search_k(train, ltest, dictionary)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Output of previous cell\n",
    "k = 2 , silhouette = 0.7600314381266555\n",
    "k = 3 , silhouette = 0.6752275340791493\n",
    "k = 4 , silhouette = 0.6140042422538549\n",
    "k = 5 , silhouette = 0.5843056284001248\n",
    "k = 6 , silhouette = 0.5634937808802221\n",
    "k = 7 , silhouette = 0.5444461357828932\n",
    "k = 8 , silhouette = 0.5345121291019872\n",
    "k = 9 , silhouette = 0.5124009337536873\n",
    "k = 10 , silhouette = 0.5040697061853416\n",
    "k = 11 , silhouette = 0.49080282616663023\n",
    "k = 12 , silhouette = 0.4790508910985389\n",
    "k = 13 , silhouette = 0.4914963311174731\n",
    "k = 14 , silhouette = 0.458577477784802\n",
    "k = 15 , silhouette = 0.46437586037353934\n",
    "k = 16 , silhouette = 0.4657706101174737\n",
    "k = 17 , silhouette = 0.46563137263218274\n",
    "k = 18 , silhouette = 0.45814675040136654\n",
    "k = 19 , silhouette = 0.44681182325184804\n",
    "k = 20 , silhouette = 0.4404248632737023\n",
    "k = 21 , silhouette = 0.450479056001983\n",
    "k = 22 , silhouette = 0.43428431342093504\n",
    "k = 23 , silhouette = 0.4417843784799455\n",
    "k = 24 , silhouette = 0.43143907239833473\n",
    "k = 25 , silhouette = 0.4516537367356941\n",
    "k = 26 , silhouette = 0.4329791473329979\n",
    "k = 27 , silhouette = 0.4232088589462763\n",
    "k = 28 , silhouette = 0.42385696104066134\n",
    "k = 29 , silhouette = 0.4389556460149199\n",
    "k = 30 , silhouette = 0.41114286781053805\n",
    "k = 31 , silhouette = 0.4178586544421491\n",
    "k = 32 , silhouette = 0.42699089550760255\n",
    "k = 33 , silhouette = 0.42817235267779397\n",
    "k = 34 , silhouette = 0.4019865036449782\n",
    "k = 35 , silhouette = 0.4219532322367825\n",
    "k = 36 , silhouette = 0.4239512264186842\n",
    "k = 37 , silhouette = 0.41320304717442036\n",
    "k = 38 , silhouette = 0.40899663868518815\n",
    "k = 39 , silhouette = 0.4196022670687089\n",
    "k = 40 , silhouette = 0.4133526097045497\n",
    "k = 41 , silhouette = 0.4041296687698144\n",
    "k = 42 , silhouette = 0.39581897494439566\n",
    "k = 43 , silhouette = 0.41190368809835587\n",
    "k = 44 , silhouette = 0.403219261494485\n",
    "k = 45 , silhouette = 0.4089286365742654\n",
    "k = 46 , silhouette = 0.4101530433588281\n",
    "k = 47 , silhouette = 0.4043158558695186\n",
    "k = 48 , silhouette = 0.3783173863517066\n",
    "k = 49 , silhouette = 0.4163419644987627\n",
    "k = 50 , silhouette = 0.4002452419960091\n",
    "k = 51 , silhouette = 0.40872221149401494\n",
    "k = 52 , silhouette = 0.4078669034314252\n",
    "k = 53 , silhouette = 0.403135794407241\n",
    "k = 54 , silhouette = 0.399162946194608\n",
    "k = 55 , silhouette = 0.39601282052952436\n",
    "k = 56 , silhouette = 0.3851635102946601\n",
    "k = 57 , silhouette = 0.40398259675393\n",
    "k = 58 , silhouette = 0.39689044755223585\n",
    "k = 59 , silhouette = 0.3864906090049179\n",
    "k = 60 , silhouette = 0.40839095194404607\n",
    "k = 61 , silhouette = 0.4057389955374202\n",
    "k = 62 , silhouette = 0.40118669701774756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = models.ldamodel.LdaModel(train, num_topics=2, id2word = dictionary, passes=50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hard clustering: map each tweet to the topic with max probability\n",
    "clusters = [max(lda[tweet], key=lambda tup: tup[1]) for tweet in ltest if len(tweet) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of clusters\n",
    "w = [1 / len(clusters)] * len(clusters)\n",
    "pd.Series([c[0] for c in clusters]).hist(bins=100, weights=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTest = pd.DataFrame(columns=['Max Topic', 'Text'])\n",
    "orig_test.index = range(len(orig_test))\n",
    "dfTest['Max Topic'] = [c[0] for c in clusters]\n",
    "dfTest['Text'] = [orig_test[i] for i in range(len(orig_test)) if len(ltest[i]) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two derived topics seems to have an interesting side-effect: the classifier acts as Trump's rant detector. It infers 1 when Trump attacks a controversial issue in his tweet, generally defending himself or belittling his opponents (Clinton, Obama, the Democrats, the FBI CEO...) in a manner that might resemble an angry rant, targeted to awaken people's anger. It is not unusual to read keywords such as \"FAKE NEWS\" or \"rigged system\". \n",
    "\n",
    "Examples: \n",
    "1. \"FAKE NEWS media knowingly doesn't tell the truth. A great danger to our country. The failing @nytimes has become a joke. Likewise @CNN. Sad!\"\n",
    "\n",
    "2. \"What is our country coming to when a judge can halt a Homeland Security travel ban and anyone, even with bad intentions, can come into U.S.?\"\n",
    "\n",
    "3. \"James Comey will be replaced by someone who will do a far better job, bringing back the spirit and prestige of the FBI.\"\n",
    "\n",
    "4. \"Karen Handle's opponent in #GA06 can't even vote in the district he wants to represent....\"\n",
    "\n",
    "5. \"Everybody is asking why the Justice Department (and FBI) isn't looking into all of the dishonesty going on with Crooked Hillary & the Dems.. \"\n",
    "\n",
    "In contrast, we observe a completely different pattern in the other cluster. Trump glorifies and thanks either his supporters, his government or even his family. He celebrates having met \"great people\" or festivities. In this cluster we observe a Trump that inspires people hope. Frequent keywords are \"honor\", \"hope\", \"pray\", \"God\", \"kind\", \"jobs\"...\n",
    "\n",
    "Examples: \n",
    "\n",
    "1. \"My warmest condolences and sympathies to the victims and families of the terrible Las Vegas shooting. God bless you\"\n",
    "\n",
    "2. \"Getting ready to celebrate the 4th of July with a big crowd at the White House. Happy 4th to everyone. Our country will grow and prosper! \"\n",
    "\n",
    "3. \"Today on #NationalAgDay, we honor our great American farmers & ranchers. Their hard work & dedication are ingrained\"\n",
    "\n",
    "4. \"Thank you for such a wonderful and unforgettable visit, Prime Minister @Netanyahu and @PresidentRuvi.\"\n",
    "\n",
    "5. \"Nick Adams, \"Retaking America\"  \"Best things of this presidency aren't reported about. Convinced this will be perhaps best presidency ever.\" \"\n",
    "\n",
    "For more examples please look through files \"topic0.txt\" and \"topic1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testTopic(dfTest, i):\n",
    "    group = dfTest[dfTest['Max Topic'] == i]['Text']\n",
    "    group.apply(lambda x: print(x, \"\\n\"))\n",
    "    print(\"frequency:\", len(group) / len(dfTest) * 100, \"%\")\n",
    "\n",
    "# To check out the output of this cell consult \"Topic0.txt\"\n",
    "testTopic(dfTest, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To check out the output of this cell consult \"Topic1.txt\"\n",
    "testTopic(dfTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda.show_topics(num_words=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Output of previous cell\n",
    "[(0,\n",
    "  '0.021*\"great\" + 0.016*\"thank\" + 0.014*\"today\" + 0.011*\"presid\" + 0.009*\"will\" + 0.008*\"meet\" + 0.008*\"honor\" + 0.007*\"nation\" + 0.007*\"state\" + 0.007*\"america\" + 0.006*\"day\" + 0.006*\"unit\" + 0.006*\"@realdonaldtrump\" + 0.005*\"trump\" + 0.005*\"peopl\" + 0.004*\"welcom\" + 0.004*\"american\" + 0.004*\"@whitehous\" + 0.004*\"happi\" + 0.004*\"order\" + 0.004*\"just\" + 0.004*\"first\" + 0.004*\"u.\" + 0.004*\"forward\" + 0.004*\"militari\" + 0.004*\"join\" + 0.004*\"new\" + 0.003*\"women\" + 0.003*\"look\" + 0.003*\"@potu\" + 0.003*\"live\" + 0.003*\"@flotu\" + 0.003*\"minist\" + 0.003*\"congratul\" + 0.003*\"wonder\" + 0.003*\"countri\" + 0.003*\"full\" + 0.003*\"prime\" + 0.003*\"famili\" + 0.003*\"#usa\" + 0.003*\"job\" + 0.003*\"texa\" + 0.003*\"morn\" + 0.003*\"secur\" + 0.003*\"white\" + 0.003*\"work\" + 0.003*\"help\" + 0.003*\"world\" + 0.002*\"melania\" + 0.002*\"men\" + 0.002*\"law\" + 0.002*\"watch\" + 0.002*\"protect\" + 0.002*\"attack\" + 0.002*\"court\" + 0.002*\"korea\" + 0.002*\"hous\" + 0.002*\"leader\" + 0.002*\"safe\" + 0.002*\"everyon\" + 0.002*\"announc\" + 0.002*\"secretari\" + 0.002*\"god\" + 0.002*\"terror\" + 0.002*\"beauti\" + 0.002*\"hero\" + 0.002*\"respond\" + 0.002*\"presidenti\" + 0.002*\"must\" + 0.002*\"host\" + 0.002*\"head\" + 0.002*\"@vp\" + 0.002*\"@scavino45\" + 0.002*\"much\" + 0.002*\"remark\" + 0.002*\"get\" + 0.002*\"gener\" + 0.002*\"execut\" + 0.002*\"donald\" + 0.002*\"support\" + 0.002*\"time\" + 0.002*\"bless\" + 0.002*\"readi\" + 0.002*\"leav\" + 0.002*\"mani\" + 0.002*\"togeth\" + 0.002*\"serv\" + 0.002*\"ban\" + 0.002*\"discuss\" + 0.002*\"brave\" + 0.002*\"prayer\" + 0.002*\"see\" + 0.002*\"offic\" + 0.002*\"wall\" + 0.002*\"rememb\" + 0.002*\"proud\" + 0.002*\"hurrican\" + 0.002*\"veteran\" + 0.002*\"right\" + 0.002*\"even\"'),\n",
    " (1,\n",
    "  '0.019*\"will\" + 0.012*\"great\" + 0.010*\"news\" + 0.009*\"fake\" + 0.008*\"big\" + 0.008*\"job\" + 0.007*\"tax\" + 0.007*\"now\" + 0.007*\"peopl\" + 0.006*\"get\" + 0.006*\"republican\" + 0.006*\"year\" + 0.006*\"media\" + 0.006*\"just\" + 0.006*\"democrat\" + 0.006*\"u.\" + 0.005*\"make\" + 0.005*\"countri\" + 0.005*\"senat\" + 0.005*\"elect\" + 0.005*\"vote\" + 0.005*\"time\" + 0.005*\"american\" + 0.005*\"work\" + 0.005*\"mani\" + 0.005*\"russia\" + 0.004*\"trump\" + 0.004*\"healthcar\" + 0.004*\"cut\" + 0.004*\"want\" + 0.004*\"obamacar\" + 0.004*\"dem\" + 0.004*\"@foxandfriend\" + 0.004*\"never\" + 0.004*\"one\" + 0.004*\"even\" + 0.004*\"deal\" + 0.004*\"can\" + 0.004*\"bad\" + 0.003*\"stori\" + 0.003*\"report\" + 0.003*\"back\" + 0.003*\"hard\" + 0.003*\"much\" + 0.003*\"america\" + 0.003*\"come\" + 0.003*\"good\" + 0.003*\"total\" + 0.003*\"win\" + 0.003*\"look\" + 0.003*\"made\" + 0.003*\"bill\" + 0.003*\"new\" + 0.003*\"like\" + 0.003*\"take\" + 0.003*\"obama\" + 0.003*\"fail\" + 0.003*\"sinc\" + 0.003*\"talk\" + 0.003*\"go\" + 0.003*\"must\" + 0.003*\"said\" + 0.003*\"hillari\" + 0.003*\"thing\" + 0.003*\"ever\" + 0.003*\"state\" + 0.003*\"hous\" + 0.003*\"china\" + 0.003*\"border\" + 0.002*\"north\" + 0.002*\"clinton\" + 0.002*\"way\" + 0.002*\"say\" + 0.002*\"@foxnew\" + 0.002*\"trade\" + 0.002*\"record\" + 0.002*\"high\" + 0.002*\"administr\" + 0.002*\"market\" + 0.002*\"korea\" + 0.002*\"realli\" + 0.002*\"better\" + 0.002*\"help\" + 0.002*\"stock\" + 0.002*\"happen\" + 0.002*\"last\" + 0.002*\"secur\" + 0.002*\"plan\" + 0.002*\"russian\" + 0.002*\"done\" + 0.002*\"interview\" + 0.002*\"nation\" + 0.002*\"rate\" + 0.002*\"repeal\" + 0.002*\"let\" + 0.002*\"replac\" + 0.002*\"see\" + 0.002*\"need\" + 0.002*\"chang\" + 0.002*\"massiv\"')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show Clustering in detail\n",
    "i = 0\n",
    "for tweet in ltest:\n",
    "    print(orig_test.iloc[i], \"\\n\")\n",
    "    print(sorted(lda[tweet], key=lambda tup: tup[1], reverse=True), \"\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lda.save(fname=\"LDAModel2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dfTest.to_csv(\"Test Sample_2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
